{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline \n",
    "import os\n",
    "import gc\n",
    "import time \n",
    "from math import log\n",
    "path = \"/home/ec2-user/Sanjay/main/credit_risk/data/competitions/home-credit-default-risk/\"\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :  (307511, 121) (48744, 121) (48744, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path + 'application_train.csv')\n",
    "test = pd.read_csv(path + 'application_test.csv')\n",
    "sample_submission = pd.read_csv(path + 'sample_submission.csv')\n",
    "y = data['TARGET']\n",
    "del data['TARGET']\n",
    "print('Shapes : ', data.shape, test.shape, sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [f for f in data.columns if data[f].dtype == 'object']\n",
    "for f_ in categorical_feats:\n",
    "    data[f_], indexer = pd.factorize(data[f_])\n",
    "    test[f_] = indexer.get_indexer(test[f_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_buro = pd.read_csv(path + 'features/' + 'avg_buro.csv')\n",
    "avg_prev = pd.read_csv(path + 'features/' + 'avg_prev.csv')\n",
    "avg_pos = pd.read_csv(path + 'features/' + 'avg_pos.csv')\n",
    "avg_cc_bal = pd.read_csv(path + 'features/' + 'avg_cc_bal.csv')\n",
    "avg_inst = pd.read_csv(path + 'features/' + 'avg_inst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22590, (307511, 380), (48744, 380))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.merge(right=avg_buro, how='left', on='SK_ID_CURR')  \n",
    "data = data.merge(right=avg_prev, how='left', on='SK_ID_CURR')\n",
    "data = data.merge(right=avg_pos, how='left', on='SK_ID_CURR')\n",
    "data = data.merge(right=avg_cc_bal, how='left', on='SK_ID_CURR')\n",
    "data = data.merge(right=avg_inst, how='left', on='SK_ID_CURR')\n",
    "\n",
    "test = test.merge(right=avg_buro, how='left', on='SK_ID_CURR') \n",
    "test = test.merge(right=avg_prev, how='left', on='SK_ID_CURR')\n",
    "test = test.merge(right=avg_pos, how='left', on='SK_ID_CURR')\n",
    "test = test.merge(right=avg_cc_bal, how='left', on='SK_ID_CURR')\n",
    "test = test.merge(right=avg_inst, how='left', on='SK_ID_CURR')\n",
    "gc.collect(), data.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "test = test.fillna(0)\n",
    "for i in data.columns:\n",
    "    if data[i].describe()[1] > 1000 and data[i].describe()[3]>=0 and test[i].describe()[3]>=0:\n",
    "        data[i] = data[i].map(lambda x : log(1+x))\n",
    "        test[i] = test[i].map(lambda x : log(1+x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 50\n",
    "}\n",
    "iteration = 6000\n",
    "vrbse = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model(X_tr, y_tr, X_va, y_va, fold, test):\n",
    "    tr_data = lgb.Dataset(X_tr, label=y_tr, categorical_feature=categorical_feats)\n",
    "    va_data = lgb.Dataset(X_va, label=y_va, categorical_feature=categorical_feats, reference=tr_data)\n",
    "    \n",
    "    model = lgb.train(parameters,\n",
    "                      tr_data,\n",
    "                      valid_sets=va_data,\n",
    "                      num_boost_round=iteration,\n",
    "                      early_stopping_rounds=120,\n",
    "                      verbose_eval=vrbse)\n",
    "    \n",
    "    test_pred = model.predict(test)\n",
    "    test_final = pd.DataFrame(test_pred, columns=['prob'+str(fold)])\n",
    "    \n",
    "    vald_pred = model.predict(X_va)\n",
    "    y_va = y_va.reset_index(drop=True)\n",
    "    valid = pd.DataFrame(vald_pred, columns=['prob'])\n",
    "    valid_final = valid.join(y_va)\n",
    "    \n",
    "    return test_final, valid_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  1  -----------------------------\n",
      "(246008, 379) (61503, 379) (246008,) (61503,) (0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.322378\n",
      "[800]\tvalid_0's binary_logloss: 0.272602\n",
      "[1200]\tvalid_0's binary_logloss: 0.25812\n",
      "[1600]\tvalid_0's binary_logloss: 0.251498\n",
      "[2000]\tvalid_0's binary_logloss: 0.247901\n",
      "[2400]\tvalid_0's binary_logloss: 0.245214\n",
      "[2800]\tvalid_0's binary_logloss: 0.24442\n",
      "Early stopping, best iteration is:\n",
      "[2708]\tvalid_0's binary_logloss: 0.244342\n",
      "(48744, 2) (48744, 1) (61503, 3) (61503, 2)\n",
      "FOLD  2  -----------------------------\n",
      "(246009, 379) (61502, 379) (246009,) (61502,) (61503, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.320753\n",
      "[800]\tvalid_0's binary_logloss: 0.270367\n",
      "[1200]\tvalid_0's binary_logloss: 0.255679\n",
      "[1600]\tvalid_0's binary_logloss: 0.248735\n",
      "[2000]\tvalid_0's binary_logloss: 0.245059\n",
      "[2400]\tvalid_0's binary_logloss: 0.242168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3966bb903086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_va\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_va\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtest_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-c5ab91a43e79>\u001b[0m in \u001b[0;36mlgbm_model\u001b[0;34m(X_tr, y_tr, X_va, y_va, fold, test)\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                       \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                       verbose_eval=vrbse)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1523\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from sklearn.model_selection import KFold\n",
    "data1 = data.drop(['SK_ID_CURR'], axis=1)\n",
    "test1 = test.drop(['SK_ID_CURR'], axis=1)\n",
    "X = data1\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "kf.get_n_splits(X), kf.split(X)\n",
    "\n",
    "test_final = sample_submission[['SK_ID_CURR']]\n",
    "oof_data = pd.DataFrame(columns=['SK_ID_CURR', 'TARGET', 'prob'])\n",
    "\n",
    "fold=1\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    print(\"FOLD \", fold, \" -----------------------------\")\n",
    "    X_tr = X[X.index.isin(train_idx)]\n",
    "    y_tr = y[y.index.isin(train_idx)]\n",
    "    X_va = X[X.index.isin(test_idx)]\n",
    "    y_va = y[y.index.isin(test_idx)]\n",
    "    valid_final = data[['SK_ID_CURR']][data.index.isin(test_idx)].reset_index(drop=True)\n",
    "    print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape, oof_data.shape)\n",
    "    \n",
    "    test, valid = lgbm_model(X_tr, y_tr, X_va, y_va, fold, test1)\n",
    "    \n",
    "    test_final = test_final.join(test)\n",
    "    oof_data = oof_data.append(valid_final.join(valid))\n",
    "    \n",
    "    print(test_final.shape, test.shape, oof_data.shape, valid.shape)\n",
    "    fold = fold+1\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final['TARGET'] = test_final.iloc[:,1:].apply(lambda x : x.mean(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final[['SK_ID_CURR', 'TARGET']].to_csv(path + 'submit/' + 'lgbm4_dart.csv', index=False)\n",
    "test_final.to_csv(path + 'submit/' + 'lgbm4_all5_dart.csv', index=False)\n",
    "oof_data.to_csv(path + 'submit/' + 'oof4_dart.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(path + 'submit/' + 'lgbm4_all5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    data['rank'+str(i)] = data['prob'+str(i)].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Average'] = data.iloc[:,7:].apply(lambda x: x.mean(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Scaled_Rank'] = (data['Average'] - data['Average'].min()) / (data['Average'].max() - data['Average'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>prob1</th>\n",
       "      <th>prob2</th>\n",
       "      <th>prob3</th>\n",
       "      <th>prob4</th>\n",
       "      <th>prob5</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>rank1</th>\n",
       "      <th>rank2</th>\n",
       "      <th>rank3</th>\n",
       "      <th>rank4</th>\n",
       "      <th>rank5</th>\n",
       "      <th>Average</th>\n",
       "      <th>Scaled_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.028665</td>\n",
       "      <td>0.035021</td>\n",
       "      <td>0.037873</td>\n",
       "      <td>0.034678</td>\n",
       "      <td>0.026641</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>33160.0</td>\n",
       "      <td>29202.0</td>\n",
       "      <td>28935.0</td>\n",
       "      <td>28875.0</td>\n",
       "      <td>34709.0</td>\n",
       "      <td>30976.2</td>\n",
       "      <td>0.635546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.147218</td>\n",
       "      <td>0.128987</td>\n",
       "      <td>0.145841</td>\n",
       "      <td>0.186561</td>\n",
       "      <td>0.145623</td>\n",
       "      <td>0.150846</td>\n",
       "      <td>5845.0</td>\n",
       "      <td>7324.0</td>\n",
       "      <td>6113.0</td>\n",
       "      <td>3822.0</td>\n",
       "      <td>5958.0</td>\n",
       "      <td>5812.4</td>\n",
       "      <td>0.119221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.025891</td>\n",
       "      <td>0.032717</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>35102.0</td>\n",
       "      <td>30571.0</td>\n",
       "      <td>33356.0</td>\n",
       "      <td>34587.0</td>\n",
       "      <td>27817.0</td>\n",
       "      <td>32286.6</td>\n",
       "      <td>0.662433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.048081</td>\n",
       "      <td>0.049728</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.034224</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>22766.0</td>\n",
       "      <td>22288.0</td>\n",
       "      <td>31023.0</td>\n",
       "      <td>29716.0</td>\n",
       "      <td>29757.0</td>\n",
       "      <td>27110.0</td>\n",
       "      <td>0.556217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.154589</td>\n",
       "      <td>0.172926</td>\n",
       "      <td>0.182148</td>\n",
       "      <td>0.157157</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>0.160507</td>\n",
       "      <td>5387.0</td>\n",
       "      <td>4516.0</td>\n",
       "      <td>4134.0</td>\n",
       "      <td>5195.0</td>\n",
       "      <td>6695.0</td>\n",
       "      <td>5185.4</td>\n",
       "      <td>0.106356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR     prob1     prob2     prob3     prob4     prob5    TARGET  \\\n",
       "0      100001  0.028665  0.035021  0.037873  0.034678  0.026641  0.032576   \n",
       "1      100005  0.147218  0.128987  0.145841  0.186561  0.145623  0.150846   \n",
       "2      100013  0.025891  0.032717  0.030674  0.026015  0.037538  0.030567   \n",
       "3      100028  0.048081  0.049728  0.034278  0.033290  0.034224  0.039920   \n",
       "4      100038  0.154589  0.172926  0.182148  0.157157  0.135714  0.160507   \n",
       "\n",
       "     rank1    rank2    rank3    rank4    rank5  Average  Scaled_Rank  \n",
       "0  33160.0  29202.0  28935.0  28875.0  34709.0  30976.2     0.635546  \n",
       "1   5845.0   7324.0   6113.0   3822.0   5958.0   5812.4     0.119221  \n",
       "2  35102.0  30571.0  33356.0  34587.0  27817.0  32286.6     0.662433  \n",
       "3  22766.0  22288.0  31023.0  29716.0  29757.0  27110.0     0.556217  \n",
       "4   5387.0   4516.0   4134.0   5195.0   6695.0   5185.4     0.106356  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TARGET'] = data.iloc[:,7:].apply(lambda x : x.mean(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['SK_ID_CURR', 'TARGET']].to_csv(path + 'submit/' + 'lgbm4_rank_normalized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

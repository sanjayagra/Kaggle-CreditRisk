{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline \n",
    "import os\n",
    "import gc\n",
    "path = \"/home/ec2-user/Sanjay/main/credit_risk/data/competitions/home-credit-default-risk/\"\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27299925, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, (817395, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro_bal = pd.read_csv(path + 'bureau_balance.csv')\n",
    "buro_bal = pd.concat([buro_bal, pd.get_dummies(buro_bal.STATUS, prefix='buro_bal_status')], axis=1).drop('STATUS', axis=1)\n",
    "print(buro_bal.shape)\n",
    "\n",
    "buro_counts = buro_bal[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n",
    "buro_bal['buro_count'] = buro_bal['SK_ID_BUREAU'].map(buro_counts['MONTHS_BALANCE'])\n",
    "avg_buro_bal = buro_bal.groupby('SK_ID_BUREAU').mean()\n",
    "avg_buro_bal.columns = ['avg_buro_' + f_ for f_ in avg_buro_bal.columns]\n",
    "avg_buro_bal.reset_index().to_csv(path + 'features/' + 'avg_buro_bal.csv', index=False)\n",
    "del buro_bal\n",
    "gc.collect(), avg_buro_bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, (305811, 46))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro = pd.read_csv(path + 'bureau.csv')\n",
    "buro_credit_active_dum = pd.get_dummies(buro.CREDIT_ACTIVE, prefix='ca_')\n",
    "buro_credit_currency_dum = pd.get_dummies(buro.CREDIT_CURRENCY, prefix='cu_')\n",
    "buro_credit_type_dum = pd.get_dummies(buro.CREDIT_TYPE, prefix='ty_')\n",
    "buro_full = pd.concat([buro, buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum], axis=1)\n",
    "\n",
    "buro_full = buro_full.merge(right=avg_buro_bal.reset_index(), how='left', on='SK_ID_BUREAU', suffixes=('', '_bur_bal'))\n",
    "nb_bureau_per_curr = buro_full[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "buro_full['SK_ID_BUREAU'] = buro_full['SK_ID_CURR'].map(nb_bureau_per_curr['SK_ID_BUREAU'])\n",
    "avg_buro = buro_full.groupby('SK_ID_CURR').mean()\n",
    "avg_buro.reset_index().to_csv(path + 'features/' + 'avg_buro.csv', index=False)\n",
    "del buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum, buro, buro_full\n",
    "gc.collect(), avg_buro.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, (338857, 163))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = pd.read_csv(path + 'previous_application.csv')\n",
    "prev_cat_features = [f_ for f_ in prev.columns if prev[f_].dtype == 'object']\n",
    "prev_dum = pd.DataFrame()\n",
    "for f_ in prev_cat_features:\n",
    "        prev_dum = pd.concat([prev_dum, pd.get_dummies(prev[f_], prefix=f_).astype(np.uint8)], axis=1)\n",
    "        \n",
    "prev = pd.concat([prev, prev_dum], axis=1)\n",
    "nb_prev_per_curr = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "prev['SK_ID_PREV'] = prev['SK_ID_CURR'].map(nb_prev_per_curr['SK_ID_PREV'])\n",
    "\n",
    "avg_prev = prev.groupby('SK_ID_CURR').mean()\n",
    "avg_prev.reset_index().to_csv(path + 'features/' + 'avg_prev.csv', index=False)\n",
    "del prev, prev_dum\n",
    "gc.collect(), avg_prev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, (337252, 15))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv(path + 'POS_CASH_balance.csv')\n",
    "pos = pd.concat([pos, pd.get_dummies(pos['NAME_CONTRACT_STATUS'])], axis=1)\n",
    "nb_prevs = pos[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "pos['SK_ID_PREV'] = pos['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "avg_pos = pos.groupby('SK_ID_CURR').mean()\n",
    "avg_pos.reset_index().to_csv(path + 'features/' + 'avg_pos.csv', index=False)\n",
    "del pos, nb_prevs\n",
    "gc.collect(), avg_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, (103558, 28))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_bal = pd.read_csv(path + 'credit_card_balance.csv')\n",
    "cc_bal = pd.concat([cc_bal, pd.get_dummies(cc_bal['NAME_CONTRACT_STATUS'], prefix='cc_bal_status_')], axis=1)\n",
    "nb_prevs = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "cc_bal['SK_ID_PREV'] = cc_bal['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "avg_cc_bal = cc_bal.groupby('SK_ID_CURR').mean()\n",
    "avg_cc_bal.columns = ['cc_bal_' + f_ for f_ in avg_cc_bal.columns]\n",
    "avg_cc_bal.reset_index().to_csv(path + 'features/' + 'avg_cc_bal.csv', index=False)\n",
    "del cc_bal, nb_prevs\n",
    "gc.collect(), avg_cc_bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, (339587, 7))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst = pd.read_csv(path + 'installments_payments.csv')\n",
    "nb_prevs = inst[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "inst['SK_ID_PREV'] = inst['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "avg_inst = inst.groupby('SK_ID_CURR').mean()\n",
    "avg_inst.columns = ['inst_' + f_ for f_ in avg_inst.columns]\n",
    "avg_inst.reset_index().to_csv(path + 'features/' + 'avg_inst.csv', index=False)\n",
    "del inst, nb_prevs\n",
    "gc.collect(), avg_inst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :  (307511, 121) (48744, 121) (48744, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path + 'application_train.csv')\n",
    "test = pd.read_csv(path + 'application_test.csv')\n",
    "sample_submission = pd.read_csv(path + 'sample_submission.csv')\n",
    "y = data['TARGET']\n",
    "del data['TARGET']\n",
    "print('Shapes : ', data.shape, test.shape, sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [f for f in data.columns if data[f].dtype == 'object']\n",
    "for f_ in categorical_feats:\n",
    "    data[f_], indexer = pd.factorize(data[f_])\n",
    "    test[f_] = indexer.get_indexer(test[f_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, (307511, 380), (48744, 380))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')  \n",
    "data = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "data = data.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "data = data.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "\n",
    "test = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR') \n",
    "test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "test = test.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "test = test.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "test = test.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "gc.collect(), data.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 50\n",
    "}\n",
    "iteration = 5000\n",
    "vrbse = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model(X_tr, y_tr, X_va, y_va, fold, test):\n",
    "    tr_data = lgb.Dataset(X_tr, label=y_tr, categorical_feature=categorical_feats)\n",
    "    va_data = lgb.Dataset(X_va, label=y_va, categorical_feature=categorical_feats, reference=tr_data)\n",
    "    \n",
    "    model = lgb.train(parameters,\n",
    "                      tr_data,\n",
    "                      valid_sets=va_data,\n",
    "                      num_boost_round=iteration,\n",
    "                      early_stopping_rounds=120,\n",
    "                      verbose_eval=vrbse)\n",
    "    \n",
    "    test_pred = model.predict(test)\n",
    "    test_final = pd.DataFrame(test_pred, columns=['prob'+str(fold)])\n",
    "    \n",
    "    vald_pred = model.predict(X_va)\n",
    "    y_va = y_va.reset_index(drop=True)\n",
    "    valid = pd.DataFrame(vald_pred, columns=['prob'])\n",
    "    valid_final = valid.join(y_va)\n",
    "    \n",
    "    return test_final, valid_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  1  -----------------------------\n",
      "(276759, 379) (30752, 379) (276759,) (30752,) (0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.384871\n",
      "[800]\tvalid_0's binary_logloss: 0.294381\n",
      "[1200]\tvalid_0's binary_logloss: 0.264707\n",
      "[1600]\tvalid_0's binary_logloss: 0.253976\n",
      "[2000]\tvalid_0's binary_logloss: 0.249207\n",
      "[2400]\tvalid_0's binary_logloss: 0.246507\n",
      "[2800]\tvalid_0's binary_logloss: 0.244699\n",
      "[3200]\tvalid_0's binary_logloss: 0.243406\n",
      "[3600]\tvalid_0's binary_logloss: 0.242476\n",
      "[4000]\tvalid_0's binary_logloss: 0.241766\n",
      "[4400]\tvalid_0's binary_logloss: 0.241195\n",
      "[4800]\tvalid_0's binary_logloss: 0.240783\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.240589\n",
      "(48744, 2) (48744, 1) (30752, 3) (30752, 2)\n",
      "FOLD  2  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (30752, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.385574\n",
      "[800]\tvalid_0's binary_logloss: 0.295404\n",
      "[1200]\tvalid_0's binary_logloss: 0.265904\n",
      "[1600]\tvalid_0's binary_logloss: 0.255385\n",
      "[2000]\tvalid_0's binary_logloss: 0.250739\n",
      "[2400]\tvalid_0's binary_logloss: 0.248253\n",
      "[2800]\tvalid_0's binary_logloss: 0.246633\n",
      "[3200]\tvalid_0's binary_logloss: 0.245464\n",
      "[3600]\tvalid_0's binary_logloss: 0.244588\n",
      "[4000]\tvalid_0's binary_logloss: 0.243882\n",
      "[4400]\tvalid_0's binary_logloss: 0.243351\n",
      "[4800]\tvalid_0's binary_logloss: 0.242943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.24276\n",
      "(48744, 3) (48744, 1) (61503, 3) (30751, 2)\n",
      "FOLD  3  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (61503, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.38213\n",
      "[800]\tvalid_0's binary_logloss: 0.29005\n",
      "[1200]\tvalid_0's binary_logloss: 0.259474\n",
      "[1600]\tvalid_0's binary_logloss: 0.248275\n",
      "[2000]\tvalid_0's binary_logloss: 0.243253\n",
      "[2400]\tvalid_0's binary_logloss: 0.24053\n",
      "[2800]\tvalid_0's binary_logloss: 0.238776\n",
      "[3200]\tvalid_0's binary_logloss: 0.237594\n",
      "[3600]\tvalid_0's binary_logloss: 0.236783\n",
      "[4000]\tvalid_0's binary_logloss: 0.236192\n",
      "[4400]\tvalid_0's binary_logloss: 0.235746\n",
      "[4800]\tvalid_0's binary_logloss: 0.23545\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.235284\n",
      "(48744, 4) (48744, 1) (92254, 3) (30751, 2)\n",
      "FOLD  4  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (92254, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.385956\n",
      "[800]\tvalid_0's binary_logloss: 0.29572\n",
      "[1200]\tvalid_0's binary_logloss: 0.266166\n",
      "[1600]\tvalid_0's binary_logloss: 0.255496\n",
      "[2000]\tvalid_0's binary_logloss: 0.250741\n",
      "[2400]\tvalid_0's binary_logloss: 0.248052\n",
      "[2800]\tvalid_0's binary_logloss: 0.24634\n",
      "[3200]\tvalid_0's binary_logloss: 0.245132\n",
      "[3600]\tvalid_0's binary_logloss: 0.244258\n",
      "[4000]\tvalid_0's binary_logloss: 0.24358\n",
      "[4400]\tvalid_0's binary_logloss: 0.24308\n",
      "[4800]\tvalid_0's binary_logloss: 0.242687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.242522\n",
      "(48744, 5) (48744, 1) (123005, 3) (30751, 2)\n",
      "FOLD  5  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (123005, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.384275\n",
      "[800]\tvalid_0's binary_logloss: 0.293115\n",
      "[1200]\tvalid_0's binary_logloss: 0.263023\n",
      "[1600]\tvalid_0's binary_logloss: 0.25212\n",
      "[2000]\tvalid_0's binary_logloss: 0.2472\n",
      "[2400]\tvalid_0's binary_logloss: 0.244512\n",
      "[2800]\tvalid_0's binary_logloss: 0.242759\n",
      "[3200]\tvalid_0's binary_logloss: 0.241478\n",
      "[3600]\tvalid_0's binary_logloss: 0.240536\n",
      "[4000]\tvalid_0's binary_logloss: 0.239838\n",
      "[4400]\tvalid_0's binary_logloss: 0.239268\n",
      "[4800]\tvalid_0's binary_logloss: 0.238846\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.238653\n",
      "(48744, 6) (48744, 1) (153756, 3) (30751, 2)\n",
      "FOLD  6  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (153756, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.383184\n",
      "[800]\tvalid_0's binary_logloss: 0.291736\n",
      "[1200]\tvalid_0's binary_logloss: 0.261575\n",
      "[1600]\tvalid_0's binary_logloss: 0.250628\n",
      "[2000]\tvalid_0's binary_logloss: 0.245733\n",
      "[2400]\tvalid_0's binary_logloss: 0.243057\n",
      "[2800]\tvalid_0's binary_logloss: 0.24134\n",
      "[3200]\tvalid_0's binary_logloss: 0.240183\n",
      "[3600]\tvalid_0's binary_logloss: 0.239338\n",
      "[4000]\tvalid_0's binary_logloss: 0.238695\n",
      "[4400]\tvalid_0's binary_logloss: 0.238219\n",
      "[4800]\tvalid_0's binary_logloss: 0.237879\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.237739\n",
      "(48744, 7) (48744, 1) (184507, 3) (30751, 2)\n",
      "FOLD  7  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (184507, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.384768\n",
      "[800]\tvalid_0's binary_logloss: 0.294089\n",
      "[1200]\tvalid_0's binary_logloss: 0.264286\n",
      "[1600]\tvalid_0's binary_logloss: 0.253582\n",
      "[2000]\tvalid_0's binary_logloss: 0.248913\n",
      "[2400]\tvalid_0's binary_logloss: 0.246398\n",
      "[2800]\tvalid_0's binary_logloss: 0.244799\n",
      "[3200]\tvalid_0's binary_logloss: 0.243659\n",
      "[3600]\tvalid_0's binary_logloss: 0.242854\n",
      "[4000]\tvalid_0's binary_logloss: 0.242226\n",
      "[4400]\tvalid_0's binary_logloss: 0.241726\n",
      "[4800]\tvalid_0's binary_logloss: 0.241331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.241148\n",
      "(48744, 8) (48744, 1) (215258, 3) (30751, 2)\n",
      "FOLD  8  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (215258, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.386173\n",
      "[800]\tvalid_0's binary_logloss: 0.296478\n",
      "[1200]\tvalid_0's binary_logloss: 0.267403\n",
      "[1600]\tvalid_0's binary_logloss: 0.257028\n",
      "[2000]\tvalid_0's binary_logloss: 0.252389\n",
      "[2400]\tvalid_0's binary_logloss: 0.249843\n",
      "[2800]\tvalid_0's binary_logloss: 0.248131\n",
      "[3200]\tvalid_0's binary_logloss: 0.246918\n",
      "[3600]\tvalid_0's binary_logloss: 0.246006\n",
      "[4000]\tvalid_0's binary_logloss: 0.245306\n",
      "[4400]\tvalid_0's binary_logloss: 0.244825\n",
      "[4800]\tvalid_0's binary_logloss: 0.244432\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.244272\n",
      "(48744, 9) (48744, 1) (246009, 3) (30751, 2)\n",
      "FOLD  9  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (246009, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.383385\n",
      "[800]\tvalid_0's binary_logloss: 0.291746\n",
      "[1200]\tvalid_0's binary_logloss: 0.261215\n",
      "[1600]\tvalid_0's binary_logloss: 0.250002\n",
      "[2000]\tvalid_0's binary_logloss: 0.24493\n",
      "[2400]\tvalid_0's binary_logloss: 0.242158\n",
      "[2800]\tvalid_0's binary_logloss: 0.240436\n",
      "[3200]\tvalid_0's binary_logloss: 0.239255\n",
      "[3600]\tvalid_0's binary_logloss: 0.238416\n",
      "[4000]\tvalid_0's binary_logloss: 0.237789\n",
      "[4400]\tvalid_0's binary_logloss: 0.237312\n",
      "[4800]\tvalid_0's binary_logloss: 0.236944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.236803\n",
      "(48744, 10) (48744, 1) (276760, 3) (30751, 2)\n",
      "FOLD  10  -----------------------------\n",
      "(276760, 379) (30751, 379) (276760,) (30751,) (276760, 3)\n",
      "Training until validation scores don't improve for 120 rounds.\n",
      "[400]\tvalid_0's binary_logloss: 0.384516\n",
      "[800]\tvalid_0's binary_logloss: 0.293698\n",
      "[1200]\tvalid_0's binary_logloss: 0.263875\n",
      "[1600]\tvalid_0's binary_logloss: 0.253149\n",
      "[2000]\tvalid_0's binary_logloss: 0.248324\n",
      "[2400]\tvalid_0's binary_logloss: 0.245597\n",
      "[2800]\tvalid_0's binary_logloss: 0.243925\n",
      "[3200]\tvalid_0's binary_logloss: 0.242738\n",
      "[3600]\tvalid_0's binary_logloss: 0.241906\n",
      "[4000]\tvalid_0's binary_logloss: 0.241262\n",
      "[4400]\tvalid_0's binary_logloss: 0.240748\n",
      "[4800]\tvalid_0's binary_logloss: 0.240323\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's binary_logloss: 0.240169\n",
      "(48744, 11) (48744, 1) (307511, 3) (30751, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "data1 = data.drop(['SK_ID_CURR'], axis=1)\n",
    "test1 = test.drop(['SK_ID_CURR'], axis=1)\n",
    "X = data1\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=2017)\n",
    "kf.get_n_splits(X), kf.split(X)\n",
    "\n",
    "test_final = sample_submission[['SK_ID_CURR']]\n",
    "oof_data = pd.DataFrame(columns=['SK_ID_CURR', 'TARGET', 'prob'])\n",
    "\n",
    "fold=1\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    print(\"FOLD \", fold, \" -----------------------------\")\n",
    "    X_tr = X[X.index.isin(train_idx)]\n",
    "    y_tr = y[y.index.isin(train_idx)]\n",
    "    X_va = X[X.index.isin(test_idx)]\n",
    "    y_va = y[y.index.isin(test_idx)]\n",
    "    valid_final = data[['SK_ID_CURR']][data.index.isin(test_idx)].reset_index(drop=True)\n",
    "    print(X_tr.shape, X_va.shape, y_tr.shape, y_va.shape, oof_data.shape)\n",
    "    \n",
    "    test, valid = lgbm_model(X_tr, y_tr, X_va, y_va, fold, test1)\n",
    "    \n",
    "    test_final = test_final.join(test)\n",
    "    oof_data = oof_data.append(valid_final.join(valid))\n",
    "    \n",
    "    print(test_final.shape, test.shape, oof_data.shape, valid.shape)\n",
    "    fold = fold+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final['TARGET'] = test_final.iloc[:,1:].apply(lambda x : x.mean(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final[['SK_ID_CURR', 'TARGET']].to_csv(path + 'submit/' + 'lgbm3.csv', index=False)\n",
    "oof_data.to_csv(path + 'submit/' + 'oof3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, copy\n",
    "data1 = pd.read_csv(path + 'submit/' + 'WEIGHT_AVERAGE_RANK.csv')\n",
    "data2 = pd.read_csv(path + 'submit/' + 'submission_with_selected_features.csv')\n",
    "# data = data1.copy()\n",
    "# data['TARGET'] = data1['TARGET']*0.7 + data2['TARGET']*0.3\n",
    "# data.to_csv(path + 'submit/' +'check1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['rank'] = data.TARGET.rank(method='min')\n",
    "data2['TARGET'] = (data2['rank'] - data2['rank'].min()) / (data2['rank'].max() - data2['rank'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1.copy()\n",
    "data['TARGET'] = data1['TARGET']*0.8 + data2['TARGET']*0.2\n",
    "data.to_csv(path + 'submit/' +'check1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR\n",
      "TARGET\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
